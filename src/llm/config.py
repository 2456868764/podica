import os
from typing import Dict, Optional
from pydantic_settings import BaseSettings
import torch

from logger import logger  # ä½¿ç”¨å·²é…ç½®å¥½çš„ logger

current_dir = os.path.dirname(os.path.abspath(__file__))

class ModelConfig(BaseSettings):
    """Model configuration
    https://deepinfra.com/hexgrad/Kokoro-82M
    
    """
    ROOT_DIR: str = current_dir
    # Chat model settings
    CHAT_MODEL_PATH: str = os.path.join(current_dir, "models", "tencent", "Hunyuan-7B-Instruct")

    DEVICE: str = "cuda" if torch.cuda.is_available() else "cpu"

    TTS_PROVIDER: str = os.getenv("TTS_PROVIDER", "kokoro")  # Options: kokoro, index-tts, soulx
    # Note: index-tts and soulx may require different conda environments due to package conflicts
    # Set TTS_PROVIDER environment variable to switch between them
    
    # Embedding model settings
    EMBEDDING_MODEL_PATH: str = os.path.join(current_dir, "models", "maidalun1020", "bce-embedding-base_v1")
    
    # TTS model settings
    TTS_MODEL_PATH: str = os.path.join(current_dir, "models", "microsoft", "speecht5_tts")
    TTS_VOCODER_PATH: str = os.path.join(current_dir, "models", "microsoft", "speecht5_hifigan")

    # TTS model settings
    KOKORO_MODEL_PATH: str = os.path.join(current_dir, "models", "hexgrad", "Kokoro-82M-v1.1-zh")

    # IndexTTS model settings
    INDEX_TTS_MODEL_PATH: str = os.path.join(current_dir, "checkpoints", "IndexTeam", "IndexTTS-2")
    INDEX_TTS_HF_CACHE_DIR: str = os.path.join(current_dir, "checkpoints", "hf_cache")  # Hugging Face cache directory
    
    # SoulX TTS model settings
    SOULX_MODEL_PATH: str = os.path.join(current_dir, "pretrained_models", "SoulX-Podcast-1.7B-dialect")
    SOULX_LLM_ENGINE: str = "hf"  # "hf" or "vllm"
    SOULX_FP16_FLOW: bool = False
    SOULX_SPK_TEXT_PROMPT: Optional[str] = None  # Optional reference text
    SOULX_BASE_MODEL_PATH: str = os.path.join(current_dir, "pretrained_models", "SoulX-Podcast-1.7B")
    SOULX_DIALECTAL_MODEL_PATH: str = os.path.join(current_dir, "pretrained_models", "SoulX-Podcast-1.7B-dialect")
    
    # TTS embeddings dataset settings
    EMBEDDINGS_DATASET_NAME: str = "Matthijs/cmu-arctic-xvectors"
    
    # Server settings
    HOST: str = "0.0.0.0"
    PORT: int = 9000
    
    # Voice mappings for TTS
    VOICE_MAPPINGS: Dict[str, Dict[str, str]] = {
        "speecht5": {
            "default": "0",
            "ash": "0",      # bdl (male)
            "ballad": "1",   # clb (female)
            "coral": "2",    # jmk (male)
            "sage": "3",     # ksp (male)
            "verse": "4",    # rms (male)
            # å…¼å®¹æ—§ç‰ˆæœ¬
            "alloy": "0",
            "echo": "1",
            "fable": "2",
            "onyx": "3",
            "nova": "4",
            "shimmer": "5"
        },


# CHOICES = {
# 'ğŸ‡ºğŸ‡¸ ğŸšº Heart â¤ï¸': 'af_heart',
# 'ğŸ‡ºğŸ‡¸ ğŸšº Bella ğŸ”¥': 'af_bella',
# 'ğŸ‡ºğŸ‡¸ ğŸšº Nicole ğŸ§': 'af_nicole',
# 'ğŸ‡ºğŸ‡¸ ğŸšº Aoede': 'af_aoede',
# 'ğŸ‡ºğŸ‡¸ ğŸšº Kore': 'af_kore',
# 'ğŸ‡ºğŸ‡¸ ğŸšº Sarah': 'af_sarah',
# 'ğŸ‡ºğŸ‡¸ ğŸšº Nova': 'af_nova',
# 'ğŸ‡ºğŸ‡¸ ğŸšº Sky': 'af_sky',
# 'ğŸ‡ºğŸ‡¸ ğŸšº Alloy': 'af_alloy',
# 'ğŸ‡ºğŸ‡¸ ğŸšº Jessica': 'af_jessica',
# 'ğŸ‡ºğŸ‡¸ ğŸšº River': 'af_river',
# 'ğŸ‡ºğŸ‡¸ ğŸš¹ Michael': 'am_michael',
# 'ğŸ‡ºğŸ‡¸ ğŸš¹ Fenrir': 'am_fenrir',
# 'ğŸ‡ºğŸ‡¸ ğŸš¹ Puck': 'am_puck',
# 'ğŸ‡ºğŸ‡¸ ğŸš¹ Echo': 'am_echo',
# 'ğŸ‡ºğŸ‡¸ ğŸš¹ Eric': 'am_eric',
# 'ğŸ‡ºğŸ‡¸ ğŸš¹ Liam': 'am_liam',
# 'ğŸ‡ºğŸ‡¸ ğŸš¹ Onyx': 'am_onyx',
# 'ğŸ‡ºğŸ‡¸ ğŸš¹ Santa': 'am_santa',
# 'ğŸ‡ºğŸ‡¸ ğŸš¹ Adam': 'am_adam',
# 'ğŸ‡¬ğŸ‡§ ğŸšº Emma': 'bf_emma',
# 'ğŸ‡¬ğŸ‡§ ğŸšº Isabella': 'bf_isabella',
# 'ğŸ‡¬ğŸ‡§ ğŸšº Alice': 'bf_alice',
# 'ğŸ‡¬ğŸ‡§ ğŸšº Lily': 'bf_lily',
# 'ğŸ‡¬ğŸ‡§ ğŸš¹ George': 'bm_george',
# 'ğŸ‡¬ğŸ‡§ ğŸš¹ Fable': 'bm_fable',
# 'ğŸ‡¬ğŸ‡§ ğŸš¹ Lewis': 'bm_lewis',
# 'ğŸ‡¬ğŸ‡§ ğŸš¹ Daniel': 'bm_daniel',
# 'ğŸ‡¬ğŸ‡§ ğŸšºxiaobei': 'zf_xiaobei',
# 'ğŸ‡¬ğŸ‡§ ğŸšºxiaobei': 'zf_xiaoni',
# 'ğŸ‡¬ğŸ‡§ ğŸšºxiaobei': 'zf_xiaoxiao',
# 'ğŸ‡¬ğŸ‡§ ğŸšºxiaobei': 'zf_xiaoyi',
# 'ğŸ‡¬ğŸ‡§ ğŸš¹zm_yunjian': 'zm_yunjian',
# 'ğŸ‡¬ğŸ‡§ ğŸš¹zm_yunxi': 'zm_yunxi',
# 'ğŸ‡¬ğŸ‡§ ğŸšºzm_yunxia': 'zm_yunxia',
# 'ğŸ‡¬ğŸ‡§ ğŸš¹zm_yunxi': 'zm_yunyang',
# }

        "kokoro": {
            "default": "am_liam",
            # å…¼å®¹æ—§ç‰ˆæœ¬
            "alloy": "am_liam",
            "echo": "am_echo",
            "ash": "am_michael",
            "coral":"af_aoede",
            "fable": "am_eric",
            "onyx": "am_onyx",
            "nova": "af_jessica",
            "shimmer": "bf_alice",
            "sage": "bf_lily",
            "af_heart":"af_heart",
            "af_alloy": "af_alloy",
            "af_aoede": "af_aoede",
            "af_bella":"af_bella",
            "af_jessica":"af_jessica",
            "af_kore":"af_kore",
            "af_nicole": "af_nicole",
            "af_nova":"af_nova",
            "af_river":"af_river",
            "af_sarah":"af_sarah",
            "af_sky":"af_sky",
            "am_adam":"am_adam",
            "am_echo":"am_echo",
            "am_eric":"am_eric",
            "am_fenrir":"am_fenrir",
            "am_liam":"am_liam",
            "am_michael":"am_michael",
            "am_onyx":"am_onyx",
            "am_puck":"am_puck",
            "am_santa":"am_santa"
        },

        "kokoro_zh": {
            "default": "zm_081",
            # å…¼å®¹æ—§ç‰ˆæœ¬
            "alloy": "zm_052",
            "echo": "zm_011",
            "ash": "zm_081",
            "coral":"zf_017",
            "fable": "zm_031",
            "onyx": "zm_041",
            "nova": "zm_061",
            "shimmer": "zf_027",
            "sage": "zf_083",
            "zf_xiaobei": "zf_xiaobei",
            "zf_xiaoni": "zf_xiaoni",
            "zf_xiaoxiao": "zf_xiaoxiao",
            "zf_xiaoyi": "zf_xiaoyi",
            "zm_yunjian": "zm_yunjian",
            "zm_yunxi": "zm_yunxi",
            "zm_yunxia": "zm_yunxia",
            "zm_yunyang": "zm_yunyang"
        },
        
        "index-tts": {
            "default": "example/ç”·å£°1.wav",
            # For IndexTTS, we use audio files as voice prompts
            # These should be paths to reference audio files
            "éƒ­å¾·çº²": "example/éƒ­å¾·çº².wav",
            "èœ¡ç¬”å°æ–°": "example/èœ¡ç¬”å°æ–°.wav",
            "ç”·å£°1": "example/ç”·å£°1.wav",
            "ç”·å£°2": "example/ç”·å£°2.wav",
            "å¥³ç”Ÿ_å®‰é™µå®¹":"example/å¥³ç”Ÿ_å®‰é™µå®¹.wav",
            "å¥³ç”Ÿ_æ˜å…°": "example/å¥³ç”Ÿ_æ˜å…°.wav",
            "å¥³ç”Ÿ_æ–°é—»è”æ’­": "example/å¥³ç”Ÿ_æ–°é—»è”æ’­.wav",
            "å¥³ç”Ÿ_ç”„å¬›": "example/å¥³ç”Ÿ_ç”„å¬›.wav",
            "ä½©å¥‡": "example/ä½©å¥‡.wav",
            "ç«¥å£°_ç”·": "example/ç«¥å£°_ç”·.wav",
            "ç«¥å£°_å¥³": "example/ç«¥å£°_å¥³.wav",
            "æ˜Ÿçˆ·": "example/æ˜Ÿçˆ·.wav"
        },
        
        "soulx": {
            "default": "example/ç”·å£°1.wav",
            # For IndexTTS, we use audio files as voice prompts
            # These should be paths to reference audio files
            "éƒ­å¾·çº²": "example/éƒ­å¾·çº².wav",
            "èœ¡ç¬”å°æ–°": "example/èœ¡ç¬”å°æ–°.wav",
            "ç”·å£°1": "example/ç”·å£°1.wav",
            "ç”·å£°2": "example/ç”·å£°2.wav",
            "å¥³ç”Ÿ_å®‰é™µå®¹":"example/å¥³ç”Ÿ_å®‰é™µå®¹.wav",
            "å¥³ç”Ÿ_æ˜å…°": "example/å¥³ç”Ÿ_æ˜å…°.wav",
            "å¥³ç”Ÿ_æ–°é—»è”æ’­": "example/å¥³ç”Ÿ_æ–°é—»è”æ’­.wav",
            "å¥³ç”Ÿ_ç”„å¬›": "example/å¥³ç”Ÿ_ç”„å¬›.wav",
            "ä½©å¥‡": "example/ä½©å¥‡.wav",
            "ç«¥å£°_ç”·": "example/ç«¥å£°_ç”·.wav",
            "ç«¥å£°_å¥³": "example/ç«¥å£°_å¥³.wav",
            "æ˜Ÿçˆ·": "example/æ˜Ÿçˆ·.wav",
            "ç”·ç”Ÿ_soulx1": "example/ç”·ç”Ÿ_soulx1.wav",
            "å¥³ç”Ÿ_soulx1": "example/å¥³ç”Ÿ_soulx1.wav",
        }
    }
    
    class Config:
        env_prefix = "LLM_"  # ç¯å¢ƒå˜é‡å‰ç¼€

# åˆ›å»ºå…¨å±€é…ç½®å®ä¾‹
config = ModelConfig()

if config.TTS_PROVIDER == "kokoro":
    logger.info("Loading Kokoro voices")
    voices_path = os.path.join(config.KOKORO_MODEL_PATH, "voices")
    # voice_path ç›®å½•ä¸‹ä»¥ zf, zm å¼€å¤´çš„æ–‡ä»¶
    voice_files = [f for f in os.listdir(voices_path) if f.startswith("zf_") or f.startswith("zm_")]
    # ä»æ–‡ä»¶åä¸­æå– voice_id
    voice_ids = [f.split(".")[0] for f in voice_files]
    # æ·»åŠ åˆ° VOICE_MAPPINGS["kokoro_zh"]
    for voice_id in voice_ids:
        config.VOICE_MAPPINGS["kokoro_zh"][voice_id] = voice_id
